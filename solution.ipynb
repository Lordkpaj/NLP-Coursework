{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec968f02",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "57b6969b",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  9 17:20:54 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P6000        Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| 26%   30C    P8     9W / 250W |   1239MiB / 22916MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "# check which gpu we're using\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c274c973",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6be4d541",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pandas\n",
    "\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b64f75",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "63db2fd6",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print('WARNING: You may want to change the runtime to GPU for faster training!')\n",
    "    DEVICE = 'cpu'\n",
    "else:\n",
    "    print(\"CUDA is available\")\n",
    "    DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ec437",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "93321177",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d91695",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "a0090edb",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "dpm = DontPatronizeMe('./data', './data/TEST/task4_test.tsv')\n",
    "dpm.load_task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797343d1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "1077633e",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@@24942188</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>We 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@@21968160</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gh</td>\n",
       "      <td>In Libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@@16584954</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"White House press secretary Sean Spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@@7811231</td>\n",
       "      <td>disabled</td>\n",
       "      <td>nz</td>\n",
       "      <td>Council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10464</th>\n",
       "      <td>10465</td>\n",
       "      <td>@@14297363</td>\n",
       "      <td>women</td>\n",
       "      <td>lk</td>\n",
       "      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10465</th>\n",
       "      <td>10466</td>\n",
       "      <td>@@70091353</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>ph</td>\n",
       "      <td>He added that the AFP will continue to bank on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>10467</td>\n",
       "      <td>@@20282330</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ng</td>\n",
       "      <td>\"\"\" She has one huge platform , and informatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>10468</td>\n",
       "      <td>@@16753236</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>in</td>\n",
       "      <td>\"\"\" Anja Ringgren Loven I ca n't find a word t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>10469</td>\n",
       "      <td>@@16779383</td>\n",
       "      <td>homeless</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"\"\" Guinness World Record of 540lbs of 7-layer...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10469 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      par_id      art_id     keyword country  \\\n",
       "0          1  @@24942188    hopeless      ph   \n",
       "1          2  @@21968160     migrant      gh   \n",
       "2          3  @@16584954   immigrant      ie   \n",
       "3          4   @@7811231    disabled      nz   \n",
       "4          5   @@1494111     refugee      ca   \n",
       "...      ...         ...         ...     ...   \n",
       "10464  10465  @@14297363       women      lk   \n",
       "10465  10466  @@70091353  vulnerable      ph   \n",
       "10466  10467  @@20282330     in-need      ng   \n",
       "10467  10468  @@16753236    hopeless      in   \n",
       "10468  10469  @@16779383    homeless      ie   \n",
       "\n",
       "                                                    text  label orig_label  \n",
       "0      We 're living in times of absolute insanity , ...      0          0  \n",
       "1      In Libya today , there are countless number of...      0          0  \n",
       "2      \"White House press secretary Sean Spicer said ...      0          0  \n",
       "3      Council customers only signs would be displaye...      0          0  \n",
       "4      \"\"\" Just like we received migrants fleeing El ...      0          0  \n",
       "...                                                  ...    ...        ...  \n",
       "10464  \"Sri Lankan norms and culture inhibit women fr...      0          1  \n",
       "10465  He added that the AFP will continue to bank on...      0          0  \n",
       "10466  \"\"\" She has one huge platform , and informatio...      1          3  \n",
       "10467  \"\"\" Anja Ringgren Loven I ca n't find a word t...      1          4  \n",
       "10468  \"\"\" Guinness World Record of 540lbs of 7-layer...      1          3  \n",
       "\n",
       "[10469 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpm.train_task1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b962558",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "257e4b86",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Split into train and dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6a8e1b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "c21335f3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  par_id                  label\n",
       "0   4341  [1, 0, 0, 1, 0, 0, 0]\n",
       "1   4136  [0, 1, 0, 0, 0, 0, 0]\n",
       "2  10352  [1, 0, 0, 0, 0, 1, 0]\n",
       "3   8279  [0, 0, 0, 1, 0, 0, 0]\n",
       "4   1164  [1, 0, 0, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get training set and dev set ids\n",
    "practice_splits_dir = './data/practice_splits/'\n",
    "train_ids = pd.read_csv(practice_splits_dir + 'train_semeval_parids-labels.csv')\n",
    "dev_ids = pd.read_csv(practice_splits_dir + 'dev_semeval_parids-labels.csv')\n",
    "\n",
    "# convert ids to strings\n",
    "train_ids.par_id = train_ids.par_id.astype(str)\n",
    "dev_ids.par_id = dev_ids.par_id.astype(str)\n",
    "train_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3baa1a7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "625450f3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def extract_split_data(ids_df, original_df):\n",
    "    \"\"\" ids_df is dataframe with columns 'par_id', 'label'\n",
    "        original_df is original dataframe with columns 'par_id', 'text', 'label', etc.\n",
    "    \"\"\"\n",
    "    rows = [] # will contain par_id, label and text\n",
    "    for idx in range(len(ids_df)):  \n",
    "        par_id = ids_df.par_id[idx]\n",
    "        # select row from original dataset to retrieve `text` and binary label\n",
    "        text = original_df.loc[original_df.par_id == par_id].text.values[0]\n",
    "        label = original_df.loc[original_df.par_id == par_id].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id':par_id,\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06dfafed",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "0cf74986",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>Durban 's homeless communities reconciliation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>The next immediate problem that cropped up was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>Far more important than the implications for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>To strengthen child-sensitive social protectio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8370</th>\n",
       "      <td>8380</td>\n",
       "      <td>Rescue teams search for survivors on the rubbl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>8381</td>\n",
       "      <td>The launch of ' Happy Birthday ' took place la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>8382</td>\n",
       "      <td>The unrest has left at least 20,000 people dea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>8383</td>\n",
       "      <td>You have to see it from my perspective . I may...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>8384</td>\n",
       "      <td>Yet there was one occasion when we went to the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id                                               text  label\n",
       "0      4341  The scheme saw an estimated 150,000 children f...      1\n",
       "1      4136  Durban 's homeless communities reconciliation ...      1\n",
       "2     10352  The next immediate problem that cropped up was...      1\n",
       "3      8279  Far more important than the implications for t...      1\n",
       "4      1164  To strengthen child-sensitive social protectio...      1\n",
       "...     ...                                                ...    ...\n",
       "8370   8380  Rescue teams search for survivors on the rubbl...      0\n",
       "8371   8381  The launch of ' Happy Birthday ' took place la...      0\n",
       "8372   8382  The unrest has left at least 20,000 people dea...      0\n",
       "8373   8383  You have to see it from my perspective . I may...      0\n",
       "8374   8384  Yet there was one occasion when we went to the...      0\n",
       "\n",
       "[8375 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = extract_split_data(train_ids, dpm.train_task1_df)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62fd87f4",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "4920a4d3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>Pope Francis washed and kissed the feet of Mus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330</td>\n",
       "      <td>Many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063</td>\n",
       "      <td>\"Budding chefs , like \"\" Fred \"\" , \"\" Winston ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4089</td>\n",
       "      <td>\"In a 90-degree view of his constituency , one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>10462</td>\n",
       "      <td>The sad spectacle , which occurred on Saturday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>10463</td>\n",
       "      <td>\"\"\" The Pakistani police came to our house and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>10464</td>\n",
       "      <td>\"When Marie O'Donoghue went looking for a spec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>10465</td>\n",
       "      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>10466</td>\n",
       "      <td>He added that the AFP will continue to bank on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id                                               text  label\n",
       "0      4046  We also know that they can benefit by receivin...      1\n",
       "1      1279  Pope Francis washed and kissed the feet of Mus...      1\n",
       "2      8330  Many refugees do n't want to be resettled anyw...      1\n",
       "3      4063  \"Budding chefs , like \"\" Fred \"\" , \"\" Winston ...      1\n",
       "4      4089  \"In a 90-degree view of his constituency , one...      1\n",
       "...     ...                                                ...    ...\n",
       "2089  10462  The sad spectacle , which occurred on Saturday...      0\n",
       "2090  10463  \"\"\" The Pakistani police came to our house and...      0\n",
       "2091  10464  \"When Marie O'Donoghue went looking for a spec...      0\n",
       "2092  10465  \"Sri Lankan norms and culture inhibit women fr...      0\n",
       "2093  10466  He added that the AFP will continue to bank on...      0\n",
       "\n",
       "[2094 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = extract_split_data(dev_ids, dpm.train_task1_df)\n",
    "dev_set_short = extract_split_data(dev_ids[150:250].reset_index(drop=True), dpm.train_task1_df)\n",
    "dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6062419",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2ce0a533",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Define downsampling/upsampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03478d8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "0bfaa5ff",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def downsample(train_set, ratio=2):\n",
    "    \"\"\" Downsample (majority) negative instances, so num_negative is ratio * num_positive\n",
    "        args:\n",
    "            ratio: The ratio of negative (majority) samples compared to positive (minority) samples\n",
    "    \"\"\"\n",
    "    \n",
    "    pos_samples = train_set[train_set.label==1]\n",
    "    neg_samples = train_set[train_set.label==0]\n",
    "\n",
    "    print(\"Number of positive samples:\", len(pos_samples))\n",
    "    print(\"Number of negative samples:\", len(neg_samples))\n",
    "\n",
    "    res = pd.concat([pos_samples, neg_samples[:len(pos_samples)*ratio]])\n",
    "\n",
    "    print(\"Number of negative samples after downsampling:\", len(res[res.label==0]))\n",
    "\n",
    "    return res\n",
    "\n",
    "def upsample(train_set, ratio=2):\n",
    "    \"\"\" Upsample (minority) positive instances, so num_negative is ratio * num_positive\n",
    "        args:\n",
    "            ratio: The ratio of negative (majority) samples compared to positive (minority) samples\n",
    "    \"\"\"\n",
    "    \n",
    "    pos_samples = train_set[train_set.label==1]\n",
    "    neg_samples = train_set[train_set.label==0]\n",
    "\n",
    "    print(\"Number of positive samples:\", len(pos_samples))\n",
    "    print(\"Number of negative samples:\", len(neg_samples))\n",
    "\n",
    "    res = pd.concat([pos_samples.sample(len(neg_samples)//ratio, replace=True), neg_samples])\n",
    "    res = res.reset_index(drop=True)\n",
    "\n",
    "    print(\"Number of positive samples after upsampling:\", len(res[res.label==1]))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d75c66",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "71a67059",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34678834",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "e89fb791",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PatroniseDataset(Dataset):\n",
    "    def __init__(self, tokenizer, input_set):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = input_set['text']\n",
    "        self.labels = input_set['label']\n",
    "        \n",
    "    def collate_fn(self, batch):\n",
    "        texts = []\n",
    "        labels = []\n",
    "\n",
    "        for b in batch:\n",
    "            texts.append(b['text'])\n",
    "            labels.append(b['label'])\n",
    "\n",
    "        # The maximum sequence size for BERT is 512 but here the tokenizer truncate sentences longer than 128 tokens.  \n",
    "        # We also pad shorter sentences to a length of 128 tokens\n",
    "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        encodings['labels'] =  torch.tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        return encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise IndexError\n",
    "        item = {'text': self.texts[idx],\n",
    "                'label': self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e4425",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fae825",
   "metadata": {},
   "source": [
    "Models:\n",
    "- BERT\n",
    "- RoBERTa\n",
    "- XLNet\n",
    "- DeBERTa\n",
    "\n",
    "For each, change:\n",
    "- learning_rate\n",
    "- batch_size\n",
    "- num_epochs\n",
    "- downsampling/upsampling\n",
    "- loss weighting of pos/neg samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c6157",
   "metadata": {},
   "source": [
    "## AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27b254",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5a41755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e17466",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d5f5c1c6",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "### Define Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d065294",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 21,
     "id": "24aa617a",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def predict_patronise(inputs, tokenizer, model): \n",
    "    model.eval()\n",
    "    encodings = tokenizer(inputs, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    encodings.to(DEVICE)\n",
    "    output = model(**encodings)\n",
    "    preds = torch.argmax(output.logits, axis=-1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9630fbf9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 22,
     "id": "da2f6334",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, data_loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            labels = data['label']\n",
    "            texts = data['text']\n",
    "            pred = predict_patronise(texts, tokenizer, model)\n",
    "            all_preds += pred.tolist()\n",
    "            all_labels += labels.tolist()\n",
    "\n",
    "    # with the saved predictions and labels we can compute accuracy, precision, recall and f1-score\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"Not patronising\", \"Patronising\"], output_dict=True)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eec49fc",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 25,
     "id": "e52806b0",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def display_report(report):\n",
    "    print(\"Not patronising:\")\n",
    "    for k, v in report['Not patronising'].items():\n",
    "        print(f\"{k:<10}: {v}\")\n",
    "\n",
    "    print(\"\\nPatronising:\")\n",
    "    for k, v in report['Patronising'].items():\n",
    "        print(f\"{k:<10}: {v}\")\n",
    "\n",
    "    print(\"\\nAccuracy:\", report['accuracy'])\n",
    "    print(\"\\nThe f1-score we care about:\", report['Patronising']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ea91d",
   "metadata": {},
   "source": [
    "### Define overall pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf22add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "results_filename = \"./results\"\n",
    "\n",
    "def load_results():\n",
    "    if not exists(results_filename):\n",
    "        return pd.DataFrame()\n",
    "    results = pd.read_csv(results_filename)\n",
    "    results['learning_rate'] = results['learning_rate'].astype(float)\n",
    "    results['batch_size'] = results['batch_size'].astype(int)\n",
    "    results['num_epochs'] = results['num_epochs'].astype(int)\n",
    "    results['sampling'] = results['sampling'].astype(int)\n",
    "    results['sampling_ratio'] = results['sampling_ratio'].astype(int)\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_results(results):\n",
    "    results.to_csv(results_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89ae847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_folds(train_set, n=5):\n",
    "    np.random.seed(0)\n",
    "    perm = np.random.permutation(len(train_set))\n",
    "    indexes = np.arange(len(train_set))\n",
    "    indexes = indexes[perm]\n",
    "    folds = np.array_split(indexes, n)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd604d6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "9eb1ac5f",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def main_patronise_cross_val(pretrained_model_name='bert-base-cased', learning_rate=0.0001, batch_size=32, num_epochs=3, sampling=1, sampling_ratio=2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pretrained_model_name\n",
    "        learning_rate\n",
    "        batch_size\n",
    "        num_epochs\n",
    "        sampling: (0 = use original data) (1 = downsample majority class) (2 = upsample minority class)\n",
    "        sampling_ratio: the ratio of negative (majority) samples compared to positive (minority) samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # create tokenizer for specified pretrained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "    \n",
    "    # upsample / downsample\n",
    "    train_set_sampled = downsample(train_set) if sampling == 1 else upsample(train_set) if sampling == 2 else train_set\n",
    "    \n",
    "    folds = get_folds(train_set_sampled, n=5)\n",
    "    reports = []\n",
    "    for fold in folds:\n",
    "        # split into train and val for this fold\n",
    "        val_indexes = fold\n",
    "        train_indexes = list(set(range(train_set_sampled.shape[0])) - set(val_indexes))\n",
    "        val_set_i = train_set_sampled.iloc[val_indexes].reset_index()\n",
    "        train_set_i = train_set_sampled.iloc[train_indexes].reset_index()\n",
    "        \n",
    "        # create dataset\n",
    "        train_dataset = PatroniseDataset(tokenizer, train_set_i)\n",
    "\n",
    "        # create classification model with specified pretrained model\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=2)\n",
    "\n",
    "        # train model\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = './experiment/patronise',\n",
    "            learning_rate = learning_rate,\n",
    "            logging_steps = 100,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            num_train_epochs = num_epochs,\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            model = model,                         \n",
    "            args = training_args,                 \n",
    "            train_dataset = train_dataset,                   \n",
    "            data_collator = train_dataset.collate_fn\n",
    "        )\n",
    "        trainer.train()\n",
    "\n",
    "        # evaluate model on this fold's val set\n",
    "        val_dataset = PatroniseDataset(tokenizer, val_set_i)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "        report = evaluate(model, tokenizer, val_loader)\n",
    "        reports.append(report)\n",
    "    \n",
    "    avg_report = {}\n",
    "    for lbl in ['Not patronising', 'Patronising']:\n",
    "        avg_report[lbl] = {}\n",
    "        for k in reports[0][lbl].keys():\n",
    "            avg_report[lbl][k] = sum([report[lbl][k] for report in reports]) / len(folds)\n",
    "    avg_report['accuracy'] = sum([report['accuracy'] for report in reports]) / len(folds)\n",
    "    \n",
    "    return avg_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beee6a3",
   "metadata": {},
   "source": [
    "### Base-model-choosing and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8477a90a",
   "metadata": {
    "collapsed": true,
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "57624943",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXIST\n",
      "EXIST\n",
      "EXIST\n"
     ]
    }
   ],
   "source": [
    "model_names = ['bert-base-cased', 'roberta-base', 'microsoft/deberta-base'] \n",
    "learning_rates = [0.00005, 0.0001, 0.0002, 0.0005, 0.001]\n",
    "batch_sizes = [16, 32, 64]\n",
    "num_epochses = [1, 2, 3, 4, 5]\n",
    "samplings = [(0,0), (1, 2), (2,2)] # [(fst,snd)] where fst is no sampling (0), downsampling (1) or upsampling (2); snd is sampling ratio \n",
    "\n",
    "# load results from previous experiments\n",
    "reports = load_results()\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for pretrained_model_name in model_names:\n",
    "        for batch_size in batch_sizes:\n",
    "            for num_epochs in num_epochses:\n",
    "                for (sampling, sampling_ratio) in samplings:\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    # if this configuration has already been done, skip it\n",
    "                    already_exists = not reports.empty and not reports.loc[(reports['pretrained_model_name']==pretrained_model_name) &\n",
    "                                                                   (reports['learning_rate']==learning_rate) &\n",
    "                                                                   (reports['batch_size']==batch_size) &\n",
    "                                                                   (reports['num_epochs']==num_epochs) &\n",
    "                                                                   (reports['sampling']==sampling) &\n",
    "                                                                   (reports['sampling_ratio']==sampling_ratio)].empty\n",
    "                    if already_exists:\n",
    "                        continue\n",
    "                        \n",
    "                    print(learning_rate, pretrained_model_name, batch_size, num_epochs, sampling, sampling_ratio)\n",
    "                        \n",
    "                    # perform cross validation with this base model and hyperparameter configuration\n",
    "                    report = main_patronise_cross_val(pretrained_model_name=pretrained_model_name,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_epochs=num_epochs,\n",
    "                                            sampling=sampling,\n",
    "                                            sampling_ratio=sampling_ratio)\n",
    "                    \n",
    "                    # add configuration and metrics to results dataframe; save results\n",
    "                    row = {'pretrained_model_name': pretrained_model_name,\n",
    "                           'learning_rate': learning_rate,\n",
    "                           'batch_size': batch_size,\n",
    "                           'num_epochs': num_epochs,\n",
    "                           'sampling': sampling,\n",
    "                           'sampling_ratio': sampling_ratio}\n",
    "                    print(row)\n",
    "                    display_report(report)\n",
    "                    for k, v in report['Not patronising'].items():\n",
    "                        row[f\"neg_{k}\"] = v\n",
    "                    for k, v in report['Patronising'].items():\n",
    "                        row[f\"pos_{k}\"] = v\n",
    "                    row['accuracy'] = report['accuracy']\n",
    "                    reports = reports.append(row, ignore_index=True)\n",
    "                    save_results(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17ca0ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretrained_model_name</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>sampling</th>\n",
       "      <th>sampling_ratio</th>\n",
       "      <th>neg_precision</th>\n",
       "      <th>neg_recall</th>\n",
       "      <th>neg_f1-score</th>\n",
       "      <th>neg_support</th>\n",
       "      <th>pos_precision</th>\n",
       "      <th>pos_recall</th>\n",
       "      <th>pos_f1-score</th>\n",
       "      <th>pos_support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.840367</td>\n",
       "      <td>0.868883</td>\n",
       "      <td>0.854024</td>\n",
       "      <td>317.6</td>\n",
       "      <td>0.719911</td>\n",
       "      <td>0.670027</td>\n",
       "      <td>0.692694</td>\n",
       "      <td>158.8</td>\n",
       "      <td>0.802276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.715389</td>\n",
       "      <td>0.920314</td>\n",
       "      <td>0.796504</td>\n",
       "      <td>317.6</td>\n",
       "      <td>0.229385</td>\n",
       "      <td>0.227728</td>\n",
       "      <td>0.227938</td>\n",
       "      <td>158.8</td>\n",
       "      <td>0.686843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.850487</td>\n",
       "      <td>0.878242</td>\n",
       "      <td>0.863710</td>\n",
       "      <td>317.6</td>\n",
       "      <td>0.740171</td>\n",
       "      <td>0.691064</td>\n",
       "      <td>0.713243</td>\n",
       "      <td>158.8</td>\n",
       "      <td>0.815271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916840</td>\n",
       "      <td>0.988666</td>\n",
       "      <td>0.951262</td>\n",
       "      <td>1516.2</td>\n",
       "      <td>0.356760</td>\n",
       "      <td>0.142806</td>\n",
       "      <td>0.197611</td>\n",
       "      <td>158.8</td>\n",
       "      <td>0.908299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>0.844663</td>\n",
       "      <td>0.832645</td>\n",
       "      <td>317.6</td>\n",
       "      <td>0.667664</td>\n",
       "      <td>0.629676</td>\n",
       "      <td>0.631929</td>\n",
       "      <td>158.8</td>\n",
       "      <td>0.772444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.903291</td>\n",
       "      <td>0.946907</td>\n",
       "      <td>0.918344</td>\n",
       "      <td>1516.2</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.740518</td>\n",
       "      <td>0.721444</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.878986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786553</td>\n",
       "      <td>0.975751</td>\n",
       "      <td>0.861218</td>\n",
       "      <td>1516.2</td>\n",
       "      <td>0.354115</td>\n",
       "      <td>0.372156</td>\n",
       "      <td>0.362891</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.775401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.935532</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937175</td>\n",
       "      <td>1516.2</td>\n",
       "      <td>0.878078</td>\n",
       "      <td>0.870664</td>\n",
       "      <td>0.874230</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.916277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987825</td>\n",
       "      <td>0.962299</td>\n",
       "      <td>0.974880</td>\n",
       "      <td>1516.2</td>\n",
       "      <td>0.928293</td>\n",
       "      <td>0.976102</td>\n",
       "      <td>0.951546</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.966934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992347</td>\n",
       "      <td>0.972421</td>\n",
       "      <td>0.982270</td>\n",
       "      <td>1516.2</td>\n",
       "      <td>0.947087</td>\n",
       "      <td>0.984855</td>\n",
       "      <td>0.965562</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.976608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pretrained_model_name  learning_rate  batch_size  num_epochs  sampling  \\\n",
       "0         bert-base-cased        0.00010          32           3         1   \n",
       "1         bert-base-cased        0.00020          32           3         1   \n",
       "2            roberta-base        0.00010          32           3         1   \n",
       "3         bert-base-cased        0.00010          16           1         0   \n",
       "4         bert-base-cased        0.00010          16           1         1   \n",
       "..                    ...            ...         ...         ...       ...   \n",
       "130       bert-base-cased        0.00020          64           3         2   \n",
       "131       bert-base-cased        0.00020          64           5         2   \n",
       "132       bert-base-cased        0.00005          64           1         2   \n",
       "133       bert-base-cased        0.00005          64           3         2   \n",
       "134       bert-base-cased        0.00005          64           5         2   \n",
       "\n",
       "     sampling_ratio  neg_precision  neg_recall  neg_f1-score  neg_support  \\\n",
       "0                 2       0.840367    0.868883      0.854024        317.6   \n",
       "1                 2       0.715389    0.920314      0.796504        317.6   \n",
       "2                 2       0.850487    0.878242      0.863710        317.6   \n",
       "3                 0       0.916840    0.988666      0.951262       1516.2   \n",
       "4                 2       0.827344    0.844663      0.832645        317.6   \n",
       "..              ...            ...         ...           ...          ...   \n",
       "130               2       0.903291    0.946907      0.918344       1516.2   \n",
       "131               2       0.786553    0.975751      0.861218       1516.2   \n",
       "132               2       0.935532    0.938895      0.937175       1516.2   \n",
       "133               2       0.987825    0.962299      0.974880       1516.2   \n",
       "134               2       0.992347    0.972421      0.982270       1516.2   \n",
       "\n",
       "     pos_precision  pos_recall  pos_f1-score  pos_support  accuracy  \n",
       "0         0.719911    0.670027      0.692694        158.8  0.802276  \n",
       "1         0.229385    0.227728      0.227938        158.8  0.686843  \n",
       "2         0.740171    0.691064      0.713243        158.8  0.815271  \n",
       "3         0.356760    0.142806      0.197611        158.8  0.908299  \n",
       "4         0.667664    0.629676      0.631929        158.8  0.772444  \n",
       "..             ...         ...           ...          ...       ...  \n",
       "130       0.901559    0.740518      0.721444        758.0  0.878986  \n",
       "131       0.354115    0.372156      0.362891        758.0  0.775401  \n",
       "132       0.878078    0.870664      0.874230        758.0  0.916277  \n",
       "133       0.928293    0.976102      0.951546        758.0  0.966934  \n",
       "134       0.947087    0.984855      0.965562        758.0  0.976608  \n",
       "\n",
       "[135 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports = load_results()\n",
    "reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed083f69",
   "metadata": {},
   "source": [
    "### Train with best model and optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de7cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_filename(model_name, learning_rate, batch_size, num_epochs, sampling, sampling_ratio):\n",
    "    sampling_text = f\"{'downsampling' if sampling == 1 else 'upsampling'}_{sampling_ratio}\" if sampling else \"\"\n",
    "    model_filename = f\"./models/patronise_{model_name}_{learning_rate}_{batch_size}_{num_epochs}_{sampling_text}/\"\n",
    "    return model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c171cb",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "9eb1ac5f",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def train_final_model(pretrained_model_name='bert-base-cased', learning_rate=0.0001, batch_size=64, num_epochs=3, sampling=2, sampling_ratio=2, save_model=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pretrained_model_name\n",
    "        learning_rate\n",
    "        batch_size\n",
    "        num_epochs\n",
    "        sampling: (0 = use original data) (1 = downsample majority class) (2 = upsample minority class)\n",
    "        sampling_ratio: the ratio of negative (majority) samples compared to positive (minority) samples\n",
    "        save_model: boolean value indicating whether or not to save model parameters/weights\n",
    "    \"\"\"\n",
    "    # Form model filename\n",
    "    model_filename = generate_model_filename(pretrained_model_name, learning_rate, batch_size, num_epochs, sampling, sampling_ratio)\n",
    "    \n",
    "    if exists(model_filename):\n",
    "        print(\"Model already exists\")\n",
    "        return model_filename\n",
    "    \n",
    "    # create tokenizer for specified pretrained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "    \n",
    "    # upsample / downsample\n",
    "    train_set_sampled = downsample(train_set) if sampling == 1 else upsample(train_set) if sampling == 2 else train_set\n",
    "    \n",
    "    # create dataset\n",
    "    train_dataset = PatroniseDataset(tokenizer, train_set_sampled)\n",
    "    \n",
    "    # create classification model with specified pretrained model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=2)\n",
    "    \n",
    "    # train model\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = './experiment/patronise',\n",
    "        learning_rate = learning_rate,\n",
    "        logging_steps = 100,\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        num_train_epochs = num_epochs,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model = model,                         \n",
    "        args = training_args,                 \n",
    "        train_dataset = train_dataset,                   \n",
    "        data_collator = train_dataset.collate_fn\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    trainer.save_model(model_filename)\n",
    "    return model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c8577a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best base model: bert-base-cased\n",
      "\n",
      "Optimal hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "batch_size: 64\n",
      "num_epochs: 3\n",
      "sampling: 2\n",
      "sampling_ratio: 2\n"
     ]
    }
   ],
   "source": [
    "# Get optimal hyperparameters\n",
    "reports = load_results()\n",
    "optimal_hyperparams = reports.iloc[[reports['pos_f1-score'].idxmax()]]\n",
    "\n",
    "print(\"Best base model:\", optimal_hyperparams['pretrained_model_name'].item())\n",
    "print(\"\\nOptimal hyperparameters:\")\n",
    "print(\"learning_rate:\", optimal_hyperparams['learning_rate'].item())\n",
    "print(\"batch_size:\", optimal_hyperparams['batch_size'].item())\n",
    "print(\"num_epochs:\", optimal_hyperparams['num_epochs'].item())\n",
    "print(\"sampling:\", optimal_hyperparams['sampling'].item())\n",
    "print(\"sampling_ratio:\", optimal_hyperparams['sampling_ratio'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ee9ba7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 23,
     "id": "1401a6d7",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "source": [
    "# Train final model\n",
    "final_model_filename = train_final_model(pretrained_model_name=optimal_hyperparams['pretrained_model_name'].values[0],\n",
    "                                         learning_rate=optimal_hyperparams['learning_rate'].item(),\n",
    "                                         batch_size=optimal_hyperparams['batch_size'].item(),\n",
    "                                         num_epochs=optimal_hyperparams['num_epochs'].item(),\n",
    "                                         sampling=optimal_hyperparams['sampling'].item(),\n",
    "                                         sampling_ratio=optimal_hyperparams['sampling_ratio'].item())\n",
    "\n",
    "final_tokenizer = AutoTokenizer.from_pretrained(optimal_hyperparams['pretrained_model_name'].values[0])\n",
    "final_model = AutoModelForSequenceClassification.from_pretrained(final_model_filename, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd8d6c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [00:08<00:00, 31.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not patronising:\n",
      "precision : 0.9399491094147583\n",
      "recall    : 0.97467018469657\n",
      "f1-score  : 0.9569948186528499\n",
      "support   : 1895\n",
      "\n",
      "Patronising:\n",
      "precision : 0.627906976744186\n",
      "recall    : 0.40703517587939697\n",
      "f1-score  : 0.49390243902439024\n",
      "support   : 199\n",
      "\n",
      "Accuracy: 0.9207258834765998\n",
      "\n",
      "The f1-score we care about: 0.49390243902439024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on dev set\n",
    "final_model.to(DEVICE)\n",
    "dev_dataset = PatroniseDataset(final_tokenizer, dev_set)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8)\n",
    "dev_report = evaluate(final_model, final_tokenizer, dev_loader)\n",
    "\n",
    "display_report(dev_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe8b1c",
   "metadata": {},
   "source": [
    "### Predict on held out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0be31272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_0</td>\n",
       "      <td>In the meantime , conservatives are working to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_1</td>\n",
       "      <td>In most poor households with no education chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_2</td>\n",
       "      <td>The real question is not whether immigration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3</td>\n",
       "      <td>In total , the country 's immigrant population...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4</td>\n",
       "      <td>Members of the church , which is part of Ken C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>t_3893</td>\n",
       "      <td>In a letter dated Thursday to European Commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>t_3894</td>\n",
       "      <td>They discovered that poor families with health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>t_3895</td>\n",
       "      <td>She married at 19 , to Milan ( Emil ) Badovina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>t_3896</td>\n",
       "      <td>The United Kingdom is n't going to devolve int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>t_3897</td>\n",
       "      <td>This moral battle informed the recent defectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      par_id                                               text\n",
       "0        t_0  In the meantime , conservatives are working to...\n",
       "1        t_1  In most poor households with no education chil...\n",
       "2        t_2  The real question is not whether immigration i...\n",
       "3        t_3  In total , the country 's immigrant population...\n",
       "4        t_4  Members of the church , which is part of Ken C...\n",
       "...      ...                                                ...\n",
       "3827  t_3893  In a letter dated Thursday to European Commiss...\n",
       "3828  t_3894  They discovered that poor families with health...\n",
       "3829  t_3895  She married at 19 , to Milan ( Emil ) Badovina...\n",
       "3830  t_3896  The United Kingdom is n't going to devolve int...\n",
       "3831  t_3897  This moral battle informed the recent defectio...\n",
       "\n",
       "[3832 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test set\n",
    "dpm.load_test()\n",
    "dpm.test_set_df\n",
    "\n",
    "# Drop unneeded columns\n",
    "dpm.test_set_df.drop(columns=['art_id', 'keyword', 'country'], inplace=True)\n",
    "dpm.test_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fe00fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to save predictions to an output file\n",
    "def save_predictions_to_file(preds, filename):\n",
    "    with open(filename,'w') as f:\n",
    "        for pred in preds:\n",
    "            f.write(str(pred.item())+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2b3fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:13<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved to file: final_model_test_preds.txt\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "test_preds = []\n",
    "test_batch_size = 32\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(dpm.test_set_df), test_batch_size)):\n",
    "        final_model.eval()\n",
    "        encodings = final_tokenizer([str(x) for x in dpm.test_set_df['text'][i:i+test_batch_size]], return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        encodings.to(DEVICE)\n",
    "        output = final_model(**encodings)\n",
    "        test_preds += torch.argmax(output.logits, axis=-1)\n",
    "\n",
    "test_preds_filename = 'final_model_test_preds.txt'\n",
    "save_predictions_to_file(test_preds, test_preds_filename)\n",
    "print(\"Test predictions saved to file:\", test_preds_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
