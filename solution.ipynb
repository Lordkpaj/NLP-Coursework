{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6969b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "57b6969b",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  2 02:02:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P4000        Off  | 00000000:00:05.0 Off |                  N/A |\n",
      "| 47%   42C    P8     6W / 105W |      0MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check which gpu we're using\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4d541",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6be4d541",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install pandas\n",
    "\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db2fd6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "63db2fd6",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print('WARNING: You may want to change the runtime to GPU for faster training!')\n",
    "    DEVICE = 'cpu'\n",
    "else:\n",
    "    print(\"CUDA is available\")\n",
    "    DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93321177",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "93321177",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0090edb",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "a0090edb",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "dpm = DontPatronizeMe('./data', './data')\n",
    "dpm.load_task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077633e",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "1077633e",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@@24942188</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>We 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@@21968160</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gh</td>\n",
       "      <td>In Libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@@16584954</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"White House press secretary Sean Spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@@7811231</td>\n",
       "      <td>disabled</td>\n",
       "      <td>nz</td>\n",
       "      <td>Council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10464</th>\n",
       "      <td>10465</td>\n",
       "      <td>@@14297363</td>\n",
       "      <td>women</td>\n",
       "      <td>lk</td>\n",
       "      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10465</th>\n",
       "      <td>10466</td>\n",
       "      <td>@@70091353</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>ph</td>\n",
       "      <td>He added that the AFP will continue to bank on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>10467</td>\n",
       "      <td>@@20282330</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ng</td>\n",
       "      <td>\"\"\" She has one huge platform , and informatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>10468</td>\n",
       "      <td>@@16753236</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>in</td>\n",
       "      <td>\"\"\" Anja Ringgren Loven I ca n't find a word t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>10469</td>\n",
       "      <td>@@16779383</td>\n",
       "      <td>homeless</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"\"\" Guinness World Record of 540lbs of 7-layer...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10469 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      par_id      art_id     keyword country  \\\n",
       "0          1  @@24942188    hopeless      ph   \n",
       "1          2  @@21968160     migrant      gh   \n",
       "2          3  @@16584954   immigrant      ie   \n",
       "3          4   @@7811231    disabled      nz   \n",
       "4          5   @@1494111     refugee      ca   \n",
       "...      ...         ...         ...     ...   \n",
       "10464  10465  @@14297363       women      lk   \n",
       "10465  10466  @@70091353  vulnerable      ph   \n",
       "10466  10467  @@20282330     in-need      ng   \n",
       "10467  10468  @@16753236    hopeless      in   \n",
       "10468  10469  @@16779383    homeless      ie   \n",
       "\n",
       "                                                    text  label orig_label  \n",
       "0      We 're living in times of absolute insanity , ...      0          0  \n",
       "1      In Libya today , there are countless number of...      0          0  \n",
       "2      \"White House press secretary Sean Spicer said ...      0          0  \n",
       "3      Council customers only signs would be displaye...      0          0  \n",
       "4      \"\"\" Just like we received migrants fleeing El ...      0          0  \n",
       "...                                                  ...    ...        ...  \n",
       "10464  \"Sri Lankan norms and culture inhibit women fr...      0          1  \n",
       "10465  He added that the AFP will continue to bank on...      0          0  \n",
       "10466  \"\"\" She has one huge platform , and informatio...      1          3  \n",
       "10467  \"\"\" Anja Ringgren Loven I ca n't find a word t...      1          4  \n",
       "10468  \"\"\" Guinness World Record of 540lbs of 7-layer...      1          3  \n",
       "\n",
       "[10469 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpm.train_task1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e4b86",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "257e4b86",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Split into train and dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21335f3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "c21335f3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  par_id                  label\n",
       "0   4341  [1, 0, 0, 1, 0, 0, 0]\n",
       "1   4136  [0, 1, 0, 0, 0, 0, 0]\n",
       "2  10352  [1, 0, 0, 0, 0, 1, 0]\n",
       "3   8279  [0, 0, 0, 1, 0, 0, 0]\n",
       "4   1164  [1, 0, 0, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_splits_dir = './data/practice_splits/'\n",
    "train_ids = pd.read_csv(practice_splits_dir + 'train_semeval_parids-labels.csv')\n",
    "dev_ids = pd.read_csv(practice_splits_dir + 'dev_semeval_parids-labels.csv')\n",
    "train_ids.par_id = train_ids.par_id.astype(str)\n",
    "dev_ids.par_id = dev_ids.par_id.astype(str)\n",
    "train_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625450f3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "625450f3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def extract_split_data(ids_df, original_df):\n",
    "    \"\"\" ids_df is dataframe with columns 'par_id', 'label'\n",
    "        original_df is original dataframe with columns 'par_id', 'text', 'label', etc.\n",
    "    \"\"\"\n",
    "    rows = [] # will contain par_id, label and text\n",
    "    for idx in range(len(ids_df)):  \n",
    "        par_id = ids_df.par_id[idx]\n",
    "        # select row from original dataset to retrieve `text` and binary label\n",
    "        text = original_df.loc[original_df.par_id == par_id].text.values[0]\n",
    "        label = original_df.loc[original_df.par_id == par_id].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id':par_id,\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf74986",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "0cf74986",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>Durban 's homeless communities reconciliation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>The next immediate problem that cropped up was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>Far more important than the implications for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>To strengthen child-sensitive social protectio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8370</th>\n",
       "      <td>8380</td>\n",
       "      <td>Rescue teams search for survivors on the rubbl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>8381</td>\n",
       "      <td>The launch of ' Happy Birthday ' took place la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>8382</td>\n",
       "      <td>The unrest has left at least 20,000 people dea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>8383</td>\n",
       "      <td>You have to see it from my perspective . I may...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>8384</td>\n",
       "      <td>Yet there was one occasion when we went to the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id                                               text  label\n",
       "0      4341  The scheme saw an estimated 150,000 children f...      1\n",
       "1      4136  Durban 's homeless communities reconciliation ...      1\n",
       "2     10352  The next immediate problem that cropped up was...      1\n",
       "3      8279  Far more important than the implications for t...      1\n",
       "4      1164  To strengthen child-sensitive social protectio...      1\n",
       "...     ...                                                ...    ...\n",
       "8370   8380  Rescue teams search for survivors on the rubbl...      0\n",
       "8371   8381  The launch of ' Happy Birthday ' took place la...      0\n",
       "8372   8382  The unrest has left at least 20,000 people dea...      0\n",
       "8373   8383  You have to see it from my perspective . I may...      0\n",
       "8374   8384  Yet there was one occasion when we went to the...      0\n",
       "\n",
       "[8375 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1 = extract_split_data(train_ids, dpm.train_task1_df)\n",
    "train_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920a4d3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "4920a4d3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>We also know that they can benefit by receivin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>Pope Francis washed and kissed the feet of Mus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330</td>\n",
       "      <td>Many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063</td>\n",
       "      <td>\"Budding chefs , like \"\" Fred \"\" , \"\" Winston ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4089</td>\n",
       "      <td>\"In a 90-degree view of his constituency , one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>10462</td>\n",
       "      <td>The sad spectacle , which occurred on Saturday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>10463</td>\n",
       "      <td>\"\"\" The Pakistani police came to our house and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>10464</td>\n",
       "      <td>\"When Marie O'Donoghue went looking for a spec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>10465</td>\n",
       "      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>10466</td>\n",
       "      <td>He added that the AFP will continue to bank on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id                                               text  label\n",
       "0      4046  We also know that they can benefit by receivin...      1\n",
       "1      1279  Pope Francis washed and kissed the feet of Mus...      1\n",
       "2      8330  Many refugees do n't want to be resettled anyw...      1\n",
       "3      4063  \"Budding chefs , like \"\" Fred \"\" , \"\" Winston ...      1\n",
       "4      4089  \"In a 90-degree view of his constituency , one...      1\n",
       "...     ...                                                ...    ...\n",
       "2089  10462  The sad spectacle , which occurred on Saturday...      0\n",
       "2090  10463  \"\"\" The Pakistani police came to our house and...      0\n",
       "2091  10464  \"When Marie O'Donoghue went looking for a spec...      0\n",
       "2092  10465  \"Sri Lankan norms and culture inhibit women fr...      0\n",
       "2093  10466  He added that the AFP will continue to bank on...      0\n",
       "\n",
       "[2094 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = extract_split_data(dev_ids, dpm.train_task1_df)\n",
    "dev_set_short = extract_split_data(dev_ids[150:250].reset_index(drop=True), dpm.train_task1_df)\n",
    "dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce0a533",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2ce0a533",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Downsample negative instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaa5ff",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "0bfaa5ff",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples: 794\n",
      "Number of negative samples: 7581\n",
      "Number of negative samples after downsampling: 1588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>Durban 's homeless communities reconciliation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>The next immediate problem that cropped up was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>Far more important than the implications for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>To strengthen child-sensitive social protectio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>1775</td>\n",
       "      <td>Last but not the least element of culpability ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>1776</td>\n",
       "      <td>Then , taking the art of counter-intuitive non...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>1777</td>\n",
       "      <td>Kagunga village was reported to lack necessary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>1778</td>\n",
       "      <td>\"After her parents high-profile divorce after ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>1779</td>\n",
       "      <td>\"Last night One News reported on leaked Minist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id                                               text  label\n",
       "0      4341  The scheme saw an estimated 150,000 children f...      1\n",
       "1      4136  Durban 's homeless communities reconciliation ...      1\n",
       "2     10352  The next immediate problem that cropped up was...      1\n",
       "3      8279  Far more important than the implications for t...      1\n",
       "4      1164  To strengthen child-sensitive social protectio...      1\n",
       "...     ...                                                ...    ...\n",
       "2377   1775  Last but not the least element of culpability ...      0\n",
       "2378   1776  Then , taking the art of counter-intuitive non...      0\n",
       "2379   1777  Kagunga village was reported to lack necessary...      0\n",
       "2380   1778  \"After her parents high-profile divorce after ...      0\n",
       "2381   1779  \"Last night One News reported on leaked Minist...      0\n",
       "\n",
       "[2382 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsample negative instances, so num_negative is 2 * num_positive\n",
    "\n",
    "pos_samples = train_df1[train_df1.label==1]\n",
    "neg_samples = train_df1[train_df1.label==0]\n",
    "\n",
    "print(\"Number of positive samples:\", len(pos_samples))\n",
    "print(\"Number of negative samples:\", len(neg_samples))\n",
    "\n",
    "training_set = pd.concat([pos_samples, neg_samples[:len(pos_samples)*2]])\n",
    "\n",
    "print(\"Number of negative samples after downsampling:\", len(training_set[training_set.label==0]))\n",
    "\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdda9b9",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6bdda9b9",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## BERT Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf68ee",
   "metadata": {
    "gradient": {
     "execution_count": 11,
     "id": "aedf68ee",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertPreTrainedModel, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85423e",
   "metadata": {
    "gradient": {
     "execution_count": 12,
     "id": "7b85423e",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a67059",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "71a67059",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89fb791",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "e89fb791",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2382\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PatroniseDataset(Dataset):\n",
    "    def __init__(self, tokenizer, input_set):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = input_set['text']\n",
    "        self.labels = input_set['label']\n",
    "        print(len(self.texts))\n",
    "        \n",
    "    def collate_fn(self, batch):\n",
    "        texts = []\n",
    "        labels = []\n",
    "\n",
    "        for b in batch:\n",
    "            texts.append(b['text'])\n",
    "            labels.append(b['label'])\n",
    "\n",
    "        # The maximum sequence size for BERT is 512 but here the tokenizer truncate sentences longer than 128 tokens.  \n",
    "        # We also pad shorter sentences to a length of 128 tokens\n",
    "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        encodings['label'] =  torch.tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        return encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise IndexError\n",
    "        item = {'text': self.texts[idx],\n",
    "                'label': self.labels[idx]}\n",
    "        return item\n",
    "    \n",
    "train_dataset = PatroniseDataset(tokenizer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de72c2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "81de72c2",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1109,  5471,  1486,  1126,  3555,  4214,   117,  1288,  1482,\n",
      "         1121,  2869,  2073,  1217,  1850,  1106,  2192,  1104,  1103,  1418,\n",
      "         2813,  1206,  3598,  1105,  2424,   117,  1118,  2689,  3791,  1105,\n",
      "        18844,  1150,  1163,  1152,  1156,  1730,  1618,  2491,   119,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "batch = [sample for sample in train_dataset]\n",
    "\n",
    "encodings = train_dataset.collate_fn(batch[:10])\n",
    "\n",
    "for key, value in encodings.items():\n",
    "    print(f\"{key}: {value.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1564ca",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8c1564ca",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347a511",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "c347a511",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "class BERT_patronise(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        \n",
    "        self.projection = torch.nn.Sequential(torch.nn.Dropout(0.2),\n",
    "                                              torch.nn.Linear(config.hidden_size, 2))\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None):\n",
    " \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        logits = self.projection(outputs[1])\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e53c3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ef4e53c3",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c49a5",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "808c49a5",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "\n",
    "class Trainer_patronise(Trainer):\n",
    "    def compute_loss(self, model, inputs):\n",
    "        labels = inputs.pop('label')\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(outputs.view(-1, 2), labels.view(-1))\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1ac5f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "9eb1ac5f",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def main_patronise():\n",
    "    # call our custom BERT model and pass as parameter the name of an available pretrained model\n",
    "    model = BERT_patronise.from_pretrained(\"bert-base-cased\")\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = './experiment/patronise',\n",
    "        learning_rate = 0.0001,\n",
    "        logging_steps = 100,\n",
    "        per_device_train_batch_size = 32,\n",
    "        num_train_epochs = 3,\n",
    "    )\n",
    "    trainer = Trainer_patronise(\n",
    "        model = model,                         \n",
    "        args = training_args,                 \n",
    "        train_dataset = train_dataset,                   \n",
    "        data_collator = train_dataset.collate_fn\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model('./models/bert_patronise_finetuned/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57624943",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "57624943",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "# main_patronise() # Train/fine-tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5c1c6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d5f5c1c6",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa617a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 21,
     "id": "24aa617a",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "def predict_patronise(inputs, tokenizer, model): \n",
    "    model.eval()\n",
    "    encodings = tokenizer(inputs, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    output = model(**encodings)\n",
    "    preds = torch.max(output, 1)\n",
    "    return {'prediction':preds[1], 'confidence':preds[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f6334",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 22,
     "id": "da2f6334",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model, tokenizer, data_loader):\n",
    "    total_count = 0\n",
    "    correct_count = 0 \n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            labels = data['label']\n",
    "            texts = data['text']\n",
    "            pred = predict_patronise(texts, tokenizer, model)\n",
    "            all_preds += pred['prediction'].tolist()\n",
    "            all_labels += labels.tolist()\n",
    "\n",
    "    # with the saved predictions and labels we can compute accuracy, precision, recall and f1-score\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"Not patronising\", \"Patronising\"], output_dict=True)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401a6d7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 23,
     "id": "1401a6d7",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "model_name = './models/bert_patronise_finetuned/'\n",
    "model = BERT_patronise.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d2193",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 24,
     "id": "af3d2193",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [08:09<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = PatroniseDataset(tokenizer, dev_set)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8)\n",
    "report = evaluate(model, tokenizer, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52806b0",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 25,
     "id": "e52806b0",
     "kernelId": "308f8cd4-86c5-47d4-baa3-e60c262101a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not patronising:\n",
      "precision : 0.9607163489312536\n",
      "recall    : 0.8775725593667546\n",
      "f1-score  : 0.9172642029784887\n",
      "support   : 1895\n",
      "\n",
      "Patronising:\n",
      "precision : 0.3608815426997245\n",
      "recall    : 0.6582914572864321\n",
      "f1-score  : 0.4661921708185052\n",
      "support   : 199\n"
     ]
    }
   ],
   "source": [
    "print(\"Not patronising:\")\n",
    "for k, v in report['Not patronising'].items():\n",
    "    print(f\"{k:<10}: {v}\")\n",
    "    \n",
    "print(\"\\nPatronising:\")\n",
    "for k, v in report['Patronising'].items():\n",
    "    print(f\"{k:<10}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
